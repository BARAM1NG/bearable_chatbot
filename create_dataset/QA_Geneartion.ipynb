{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 프로젝트 목적\n",
    "- 본 프로젝트는 Fine-tuning을 위한 Q-A pair 데이터셋 구축을 위한 프로젝트입니다.\n",
    "    - PDF to Text\n",
    "    - PDF to Markdown\n",
    "    - Link(Text) to Text\n",
    "    - Link(Text) to Markdown\n",
    "- GPT API를 통해 Q-A 데이터셋을 구축합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 환경 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. QA Pair 를 생성할 PDF 로드\n",
    "1. PDF 텍스트를 추출하는데 강점을 가진 함수\n",
    "    - `extract_text_from_pdf`\n",
    "    - 텍스트가 주를 이루고 있을 때, 사용한다.\n",
    "2. PDF to Markdown 함수\n",
    "    - `extract_markdown_from_pdf`\n",
    "    - 표와 텍스트가 병합하여 사용되고 있을 때 사용하면 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# 텍스트 추출에 집중: PyPDF2 라이브러리를 사용해 PDF의 모든 페이지에서 텍스트를 추출하고 청크로 나눔\n",
    "def extract_text_from_pdf(pdf_path, chunk_size=4000, chunk_overlap=150):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 추출하고 지정된 크기의 청크로 나눕니다.\n",
    "    pdf_path: PDF 파일 경로\n",
    "    chunk_size: 각 청크의 최대 문자 수 (기본값: 4000)\n",
    "    chunk_overlap: 청크 간 겹치는 문자 수 (기본값: 150)\n",
    "    return: 텍스트 청크 리스트\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    \n",
    "    # PDF 파일 열기\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        num_pages = len(reader.pages)\n",
    "        \n",
    "        # 모든 페이지의 텍스트 추출\n",
    "        for page_num in range(num_pages):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            \n",
    "            # 페이지 번호 추가\n",
    "            all_text += f\"- {page_num + 1} -\"\n",
    "            \n",
    "            # 텍스트가 있는 경우에만 추가\n",
    "            if page_text:\n",
    "                all_text += page_text\n",
    "            \n",
    "    # 텍스트를 청크로 나누기\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(all_text):\n",
    "        # 청크의 끝 위치 계산\n",
    "        end = min(start + chunk_size, len(all_text))\n",
    "        \n",
    "        # 중간에 끊기지 않도록 문장이나 단락의 끝 찾기\n",
    "        if end < len(all_text):\n",
    "            # 줄바꿈이나 마침표 등에서 끊기도록 설정\n",
    "            for delimiter in ['\\n\\n', '\\n', '. ', '? ', '! ']:\n",
    "                last_delimiter = all_text.rfind(delimiter, start, end)\n",
    "                if last_delimiter > start:\n",
    "                    end = last_delimiter + len(delimiter)\n",
    "                    break\n",
    "        \n",
    "        # 청크 추가\n",
    "        chunks.append(all_text[start:end])\n",
    "        \n",
    "        # 다음 청크의 시작 위치 (겹치는 부분 고려)\n",
    "        start = end - chunk_overlap if end < len(all_text) else end\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "elements = extract_text_from_pdf(\"../../asset/pdf/고교학점제 이해를 위한 Q & A_250325_214831.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "import os\n",
    "import nest_asyncio\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# PDF를 마크다운 형식으로 변환하고 청크로 분할하는 함수\n",
    "\n",
    "def extract_markdown_from_pdf(pdf_path, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    pymupdf4llm 라이브러리를 사용해 PDF 문서를 마크다운으로 변환하고 텍스트/표/이미지 등의 요소를 포함한 형태로 추출한 후\n",
    "    RecursiveCharacterTextSplitter를 사용하여 청크로 나눕니다.\n",
    "    pdf_path: PDF 파일 경로\n",
    "    chunk_size: 각 청크의 최대 문자 수 (기본값: 4000)\n",
    "    chunk_overlap: 청크 간 겹치는 문자 수 (기본값: 200)\n",
    "    return: 마크다운 형식의 텍스트 청크 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    # PDF 파일이 존재하는지 확인\n",
    "    print(f\"PDF 파일 로드 중: {pdf_path}\")\n",
    "    \n",
    "    # PDF 파일 로드 (LlamaMarkdownReader 직접 생성)\n",
    "    reader = pymupdf4llm.LlamaMarkdownReader()\n",
    "    docs = reader.load_data(pdf_path)\n",
    "    \n",
    "    # 모든 문서 텍스트 합치기\n",
    "    full_text = \"\"\n",
    "    for doc in docs:\n",
    "        full_text += doc.text + \"\\n\\n\"\n",
    "    \n",
    "    # RecursiveCharacterTextSplitter를 사용하여 텍스트를 청크로 나누기\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\\n-----\\n\\n\\n\\n\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(full_text)\n",
    "    \n",
    "    print(f\"총 {len(chunks)}개의 청크로 나누었습니다.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 파일 로드 중: ../create_dataset/source_data/pdf/prompt_test.pdf\n",
      "Successfully imported LlamaIndex\n",
      "총 6개의 청크로 나누었습니다.\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일 로드 및 청크로 나누기\n",
    "elements = extract_markdown_from_pdf('../create_dataset/source_data/pdf/prompt_test.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 과목 소개\n",
      "\n",
      "##### ‘공통수학1’과 ‘공통수학2’는 수학에 대한 기초 소양과 학문적 이해를 기반으로 학생 스스로 자신의 적성을 개발하여 창의성을 갖춘 사람으로 성장하기 위해 수학의 여러 영역의 기본적인 내용을 학습하는 과목이다. 특히 ‘공통수학1’은 중학교 ‘변화와 관계’ 영역에서 학습한 다항식, 방정식, 부등식이 심화되고 다양한 유형으로 다루어지며, ‘자료와 가능성’ 영역에서 학습한 경우의 수가 순열과 조합을 활용하는 방법으로 체계화된다.\n",
      "\n",
      "### 무엇을 배울까요?\n",
      "#### 40 [ 경상남도교육청]\n",
      "\n",
      "|범주 다항식 방정식과 부등식 지식·이해 경우의 수 행렬|Col2|내용 요소 다항식의 연산 나머지정리 인수분해|\n",
      "|---|---|---|\n",
      "||방정식과 부등식|복소수와 이차방정식 이차방정식과 이차함수 여러 가지 방정식과 부등식|\n",
      "||경우의 수|합의 법칙과 곱의 법칙 순열과 조합|\n",
      "||행렬|행렬과 그 연산|\n",
      "|과정·기능|다항식, 방정식과 부등식, 경우의 수, 행렬의 개념, 원리, 법칙이나 자신의 수학적 사고와 전략을 설명하기 수학적 절차를 수행하고 계산하기 적절한 전략을 사용하여 문제해결하기 이차방정식과 이차부등식을 이차함수와 연결하기 이차함수의 그래프와 직선의 위치 관계를 판단하기 다항식, 방정식과 부등식, 경우의 수, 행렬의 개념, 원리, 법칙, 성질을 탐구하기 방정식과 부등식 풀기 방정식과 부등식, 경우의 수, 행렬을 실생활과 연결하기 식과 그래프, 수학 기호, 행렬 등을 표현하기||\n"
     ]
    }
   ],
   "source": [
    "print(elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. QA Pair 생성\n",
    "- 각 LLM에 프롬프트를 다르게 하여 고품질의 QA Dataset을 만드는 AI 디스틸레이션\n",
    "    - 생성 LLM: `qa_claude` 입력된 PDF에서 QA data를 생성합니다.\n",
    "    - 비판 LLM: `critique_gpt` QA 데이터에서 질문&대답에 대한 검증 및 비판을 생성합니다.\n",
    "    - 정보 종합 LLM: `final_qa_gpt` 기존 질문&대답과 비판에 대한 정보를 종합하여 최종 QA data를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import critique_gpt, final_qa_gpt, qa_claude\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_generation_pipeline(elements: List[str], domain: str, num_questions: str = \"2\") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    전체 QA 생성 파이프라인 함수\n",
    "    \n",
    "    Parameters:\n",
    "        elements (List[str]): 텍스트 청크 목록\n",
    "        domain (str): 도메인 (예: 고교학점제)\n",
    "        num_questions (str): 각 청크당 생성할 질문 수\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, str]]: 최종 QA 쌍 목록\n",
    "    \"\"\"\n",
    "    final_qa_pairs = []\n",
    "    \n",
    "    try:\n",
    "        # 1. 초기 QA 쌍 생성\n",
    "        initial_qa_pairs = qa_claude.generate_qa_pairs(elements, domain, num_questions)\n",
    "        \n",
    "        # 2. QA 쌍에 대한 비판 생성\n",
    "        critique_qa_pair = critique_gpt.critique_qa_pairs(initial_qa_pairs, domain)\n",
    "        \n",
    "        # 3. 비판을 반영한 최종 QA 쌍 생성\n",
    "        final_qa_pairs = final_qa_gpt.generate_final_qa_pairs(critique_qa_pair, domain)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('='*50)\n",
    "        print(f\"[에러 발생] | {e} | {elements[0][:100]}...\")  # 청크의 첫 부분만 출력\n",
    "        print('='*50)\n",
    "        \n",
    "    return final_qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 PDF를 markdown으로 변환한 후, chunk 별로 질문을 생성하는 파이프라인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs(pdf_dir='./source_data/pdf/', \n",
    "                    output_dir='../output_data/',\n",
    "                    domain=\"Default\",\n",
    "                    chunk_size=500,\n",
    "                    chunk_overlap=100,\n",
    "                    questions_per_chunk=\"2\"):\n",
    "    \"\"\"\n",
    "    지정된 디렉토리에 있는 모든 PDF 파일을 처리하여 QA 셋을 생성합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        pdf_dir (str): PDF 파일이 저장된 디렉토리 경로\n",
    "        output_dir (str): 결과를 저장할 디렉토리 경로\n",
    "        domain (str): QA 생성의 도메인\n",
    "        chunk_size (int): 청크 크기\n",
    "        chunk_overlap (int): 청크 간 겹침 크기\n",
    "        questions_per_chunk (str): 각 청크당 생성할 질문 수\n",
    "    \"\"\"\n",
    "    # 출력 디렉토리가 없으면 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # PDF 파일 목록 가져오기\n",
    "    pdf_list = [f\"{pdf_dir}/{pdf}\" for pdf in os.listdir(pdf_dir) if pdf.endswith('.pdf')]\n",
    "    print(f\"총 {len(pdf_list)}개의 PDF 파일을 찾았습니다.\")\n",
    "    \n",
    "    # 모든 QA 쌍을 저장할 리스트\n",
    "    all_qa_pairs = []\n",
    "    \n",
    "    # PDF 파일별로 처리\n",
    "    for pdf_path in tqdm(pdf_list, desc=\"PDF 처리 중\"):\n",
    "        try:\n",
    "            # PDF 파일명 추출 (확장자 제외)\n",
    "            pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "            \n",
    "            print(f\"\\n[처리 시작] {pdf_name}\")\n",
    "            \n",
    "            # PDF에서 마크다운 청크 추출\n",
    "            chunks = extract_markdown_from_pdf(pdf_path, chunk_size, chunk_overlap)\n",
    "            \n",
    "            # 빈 청크 제거\n",
    "            chunks = [chunk for chunk in chunks if chunk.strip()]\n",
    "            \n",
    "            if not chunks:\n",
    "                print(f\"[주의] {pdf_name}에서 유효한 청크를 추출하지 못했습니다.\")\n",
    "                continue\n",
    "            \n",
    "            # 도메인 설정 - PDF 파일명을 기본 도메인으로 사용하거나 지정된 도메인 사용\n",
    "            current_domain = domain if domain != \"Default\" else pdf_name\n",
    "            \n",
    "            # 청크를 작은 배치로 나누어 처리 (API 호출 제한 고려)\n",
    "            batch_size = 5  # 한 번에 처리할 청크 수\n",
    "            qa_pairs = []\n",
    "            \n",
    "            for i in range(0, len(chunks), batch_size):\n",
    "                batch_chunks = chunks[i:i+batch_size]\n",
    "                print(f\"배치 처리 중: {i//batch_size + 1}/{(len(chunks)+batch_size-1)//batch_size}\")\n",
    "                \n",
    "                # QA 셋 생성\n",
    "                batch_qa_pairs = qa_generation_pipeline(batch_chunks, current_domain, questions_per_chunk)\n",
    "                qa_pairs.extend(batch_qa_pairs)\n",
    "            \n",
    "            # 각 QA 쌍에 PDF 출처 정보 추가\n",
    "            for qa_pair in qa_pairs:\n",
    "                qa_pair[\"SOURCE\"] = pdf_name\n",
    "            \n",
    "            # 전체 QA 쌍 목록에 추가\n",
    "            all_qa_pairs.extend(qa_pairs)\n",
    "            \n",
    "            # 현재 PDF의 결과를 JSONL으로 저장\n",
    "            pdf_output_path = f\"{output_dir}/{pdf_name}_qa.jsonl\"\n",
    "            with open(pdf_output_path, 'w', encoding='utf-8') as f:\n",
    "                for qa_pair in qa_pairs:\n",
    "                    f.write(json.dumps(qa_pair, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "            print(f\"[처리 완료] {pdf_name}: {len(qa_pairs)}개의 QA 쌍 생성\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[에러] {pdf_path} 처리 중 오류 발생: {str(e)}\")\n",
    "    \n",
    "    # 모든 결과를 하나의 JSONL 파일로 저장\n",
    "    all_output_path = f\"{output_dir}/all_qa_pairs.jsonl\"\n",
    "    with open(all_output_path, 'w', encoding='utf-8') as f:\n",
    "        for qa_pair in all_qa_pairs:\n",
    "            f.write(json.dumps(qa_pair, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"\\n처리 완료! 총 {len(all_qa_pairs)}개의 QA 쌍이 생성되었습니다.\")\n",
    "    print(f\"결과는 다음 위치에 저장되었습니다:\")\n",
    "    print(f\"- JSONL: {all_output_path}\")\n",
    "    \n",
    "    return all_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 1개의 PDF 파일을 찾았습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PDF 처리 중:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[처리 시작] prompt_test\n",
      "PDF 파일 로드 중: ./source_data/pdf//prompt_test.pdf\n",
      "총 6개의 청크로 나누었습니다.\n",
      "배치 처리 중: 1/2\n",
      "배치 처리 중: 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PDF 처리 중: 100%|██████████| 1/1 [01:26<00:00, 86.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[처리 완료] prompt_test: 12개의 QA 쌍 생성\n",
      "\n",
      "처리 완료! 총 12개의 QA 쌍이 생성되었습니다.\n",
      "결과는 다음 위치에 저장되었습니다:\n",
      "- JSONL: ./output_data//all_qa_pairs.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모든 PDF 처리\n",
    "qa_pairs = process_all_pdfs(\n",
    "    pdf_dir='./source_data/pdf/',\n",
    "    output_dir='./output_data/',\n",
    "    domain=\"Default\",  # \"Default\"로 설정하면 각 PDF 파일명을 도메인으로 사,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    questions_per_chunk=\"2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'QUESTION': \"공통수학1에서 '경우의 수' 영역의 핵심 개념은 무엇인가요?\",\n",
       "  'ANSWER': \"공통수학1에서 '경우의 수' 영역의 핵심 개념은 합의 법칙과 곱의 법칙, 그리고 순열과 조합입니다. 이는 중학교 '자료와 가능성' 영역에서 학습한 경우의 수를 순열과 조합을 활용하여 체계적으로 이해하는 방법입니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"공통수학1 과목에서 '방정식과 부등식' 범주에 포함되는 구체적인 내용 요소는 무엇인가요?\",\n",
       "  'ANSWER': \"공통수학1 과목에서 '방정식과 부등식' 범주에 포함되는 구체적인 내용 요소는 복소수와 이차방정식, 이차방정식과 이차함수, 여러 가지 방정식과 부등식입니다. 이는 중학교 '변화와 관계' 영역에서 학습한 방정식과 부등식의 심화된 내용으로, 다양한 유형으로 다루어집니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"공통수학2의 '도형의 방정식' 영역에서 다루는 주요 개념은 무엇인가요?\",\n",
       "  'ANSWER': \"공통수학2의 '도형의 방정식' 영역에서는 평면좌표, 직선의 방정식, 원의 방정식, 도형의 이동을 다룹니다. 이는 중학교 '도형과 측정' 영역에서 학습한 원과 직선을 방정식으로 표현하는 방법을 포함합니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': '공통수학2 과목의 과정·기능 영역에서 학생들이 수행해야 하는 함수와 관련된 활동은 무엇인가요?',\n",
       "  'ANSWER': \"공통수학2 과목의 과정·기능 영역에서 학생들은 '합성함수와 역함수 구하기' 외에도 함수의 그래프를 해석하고, 함수의 성질을 분석하는 활동을 수행해야 합니다. 이는 함수와 그래프 영역의 학습 내용과 연계된 실제적인 수학적 기능입니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"기본수학1 과목에서 '방정식과 부등식' 범주에 포함되는 주요 학습 내용은 무엇인가요?\",\n",
       "  'ANSWER': \"기본수학1 과목의 '방정식과 부등식' 범주에는 이차방정식, 이차함수, 그리고 부등식이 포함되며, 이는 중학교 '변화와 관계' 영역에서 학습한 내용을 심화하여 다룹니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"기본수학1 과목에서 '경우의 수' 영역은 어떤 내용을 다루며, 중학교에서 배운 내용과 어떻게 연결되나요?\",\n",
       "  'ANSWER': \"기본수학1 과목의 '경우의 수' 영역에서는 합의 법칙과 곱의 법칙, 순열과 조합을 다룹니다. 이는 중학교 '자료와 가능성' 영역에서 학습한 경우의 수 개념을 순열과 조합을 통해 보다 체계적으로 확장한 것입니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"기본수학2에서 '도형의 방정식' 범주에 포함되는 주요 내용 요소는 무엇인가요?\",\n",
       "  'ANSWER': \"기본수학2의 '도형의 방정식' 범주에는 평면좌표, 직선의 방정식, 원의 방정식, 그리고 도형의 이동이 포함됩니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': \"기본수학2 과목의 '함수와 그래프' 영역에서 어떤 종류의 함수를 학습하나요?\",\n",
       "  'ANSWER': \"기본수학2 과목의 '함수와 그래프' 영역에서는 함수, 유리함수, 그리고 무리함수를 학습합니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': '대수 과목에서 다루는 삼각함수의 주요 내용 요소는 무엇인가요?',\n",
       "  'ANSWER': \"대수 과목에서 다루는 삼각함수의 주요 내용 요소는 '삼각함수'와 '사인법칙 및 코사인법칙'입니다.\",\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': '대수 과목을 학습한 학생들이 얻을 수 있는 능력은 무엇인가요?',\n",
       "  'ANSWER': '대수를 학습한 학생들은 큰 수를 더 편리하게 다루고, 주기적인 성질을 이해하여 다양한 사회 현상이나 자연 현상을 수학적으로 해석하고 탐구할 수 있으며, 모든 자연수에서 성립하는 규칙의 일반성을 귀납적 추론 또는 연역적 추론을 통해 수학적으로 정당화할 수 있습니다. 또한, 문제 해결 능력과 논리적 사고력을 강화하여 복잡한 문제를 체계적으로 접근하고 해결할 수 있는 능력을 기를 수 있습니다.',\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': '고교학점제에서 졸업하기 위해 학생들이 취득해야 하는 최소 학점은 몇 학점이며, 필수로 이수해야 하는 과목들은 무엇인가요?',\n",
       "  'ANSWER': '고교학점제에서 학생들은 졸업을 위해 3년간 총 192학점 이상을 취득해야 합니다. 필수로 이수해야 하는 과목으로는 국어, 수학, 영어, 한국사, 통합사회, 통합과학, 과학탐구실험 등의 공통과목과 일반선택과목, 진로선택과목을 포함하여 교과 180학점 이상, 창의적 체험활동 12학점 이상을 이수해야 합니다.',\n",
       "  'SOURCE': 'prompt_test'},\n",
       " {'QUESTION': '학교 밖 교육의 유형에는 어떤 것들이 있으며, 각 유형에 대해 간단히 설명해 주세요. 또한, 최대 몇 학점까지 인정받을 수 있나요?',\n",
       "  'ANSWER': '학교 밖 교육의 유형에는 대학과목 선이수제(AP), 공동교육과정, 고교-대학 연계 학점인정 과목, 온라인 공동교육과정, 학교 간 공동교육과정, 지역사회 연계 교육과정 등이 있습니다. 대학과목 선이수제는 고등학생이 대학 과목을 미리 수강하는 제도이며, 공동교육과정은 여러 학교가 협력하여 운영하는 교육과정입니다. 고교-대학 연계 학점인정 과목은 고등학교와 대학이 협력하여 학점을 인정하는 과목이고, 온라인 공동교육과정은 인터넷을 통해 여러 학교가 공동으로 운영하는 교육과정입니다. 학교 간 공동교육과정은 인근 학교들이 협력하여 운영하는 교육과정이며, 지역사회 연계 교육과정은 지역사회와 협력하여 운영하는 교육과정입니다. 학생들은 학교 밖 교육을 통해 최대 64학점까지 인정받을 수 있습니다.',\n",
       "  'SOURCE': 'prompt_test'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직접 Q-A 데이터셋을 만들어서 추가하고 싶은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디버깅을 위한 데이터셋 추가\n",
    "additional_qa = [\n",
    "    {\n",
    "        \"QUESTION\": \"테디노트 유튜브 채널에 대해서 알려주세요.\",\n",
    "        \"ANSWER\": \"테디노트(TeddyNote)는 데이터 분석, 머신러닝, 딥러닝 등의 주제를 다루는 유튜브 채널입니다. 이 채널을 운영하는 이경록님은 데이터 분석과 인공지능에 대한 다양한 강의를 제공하며, 초보자도 쉽게 따라할 수 있도록 친절하게 설명합니다.\",\n",
    "    },\n",
    "    {\n",
    "        \"QUESTION\": \"랭체인 관련 튜토리얼은 어디서 찾을 수 있나요?\",\n",
    "        \"ANSWER\": \"테디노트의 위키독스 페이지에는 LangChain에 대한 다양한 한국어 튜토리얼이 제공됩니다. 링크: https://wikidocs.net/book/14314\",\n",
    "    },\n",
    "    {\n",
    "        \"QUESTION\": \"테디노트 운영자에 대해서 알려주세요\",\n",
    "        \"ANSWER\": \"테디노트(TeddyNote) 운영자는 이경록(Teddy Lee)입니다. 그는 데이터 분석, 머신러닝, 딥러닝 분야에서 활동하는 전문가로, 다양한 교육 및 강의를 통해 지식을 공유하고 있습니다. 이경록님은 여러 기업과 교육기관에서 파이썬, 데이터 분석, 텐서플로우 등 다양한 주제로 강의를 진행해 왔습니다\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa_pair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mqa_pair\u001b[49m.extend(additional_qa)\n\u001b[32m      2\u001b[39m qa_pair\n",
      "\u001b[31mNameError\u001b[39m: name 'qa_pair' is not defined"
     ]
    }
   ],
   "source": [
    "qa_pairs.extend(additional_qa)\n",
    "qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jsonl 파일로 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 기존의 qa_pair 데이터를 jsonl 형식으로 저장\n",
    "with open(\"qa_pair.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qa in qa_pair:\n",
    "        f.write(json.dumps(qa, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 저장 확인 메시지 출력\n",
    "print(f\"총 {len(qa_pair)}개의 질문-답변 쌍이 qa_pair.jsonl 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# qa_pair에 있는 QA 데이터를 모델 학습에 적합한 형식으로 변환하여 JSONL 형식으로 저장\n",
    "with open(\"qa_pair.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qa in qa_pair:\n",
    "        # 질문-답변 쌍을 instruction-input-output 형식으로 변환\n",
    "        qa_modified = {\n",
    "            \"instruction\": qa[\"QUESTION\"], # 질문 내용을 instruction 필드에 매핑\n",
    "            \"input\": \"\", # 추가 입력이 필요 없으므로 빈 문자열로 설정\n",
    "            \"output\": qa[\"ANSWER\"], # 답변 내용을 output 필드에 매핑\n",
    "        }\n",
    "        # 변환된 형식의 데이터를 JSON 문자열로 변환하여 파일에 한 줄씩 추가\n",
    "        f.write(json.dumps(qa_modified, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace datasets 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 64 examples [00:00, 16979.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# JSONL 파일 경로\n",
    "jsonl_file = \"qa_pair.jsonl\"\n",
    "\n",
    "# JSONL 파일을 Dataset으로 로드\n",
    "dataset = load_dataset(\"json\", data_files=jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1024.50ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/BARAM1NG/QA_bearable/commit/fc1a908abb6890cb6207149aa97f0f72dba8a1fa', commit_message='Upload dataset', commit_description='', oid='fc1a908abb6890cb6207149aa97f0f72dba8a1fa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/BARAM1NG/QA_bearable', endpoint='https://huggingface.co', repo_type='dataset', repo_id='BARAM1NG/QA_bearable'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# HfApi 인스턴스 생성\n",
    "api = HfApi()\n",
    "\n",
    "# 데이터셋을 업로드할 리포지토리 이름\n",
    "repo_name = \"BARAM1NG/QA_bearable\"\n",
    "\n",
    "# 데이터셋을 허브에 푸시\n",
    "dataset.push_to_hub(repo_name, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bearable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
